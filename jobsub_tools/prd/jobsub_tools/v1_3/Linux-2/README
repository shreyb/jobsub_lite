
Jobsub_tools 

A KITS product containing all the Intensity Frontier grid submission tools.

Usage:
setup jobsub_tools 
(then)
jobsub [options]
minos_jobsub [options]
minerva_jobsub [options]
nova_jobsub [options]
dagNabbit.py [options]

no need for sourcing /grid/fermiapp/......setup_(some)_condor.sh

$JOBSUB_TOOLS_DIR/docs contains additional documentation
$JOBSUB_TOOLS_DIR/test contains unit tests and usage examples


--------------------------
RELEASE NOTES
--------------------------
v1_3_7 12/23/14
====================================================
- #7567  Suppress log messages to stderr


v1_3_6  
===================================================
- #7072 Head & tail size of job's stdout and stderr is now configurable. 

v1_3_5 10/23/14
=====================================================
- #7088 mail summary of DAG node execution to users
  when --generate-email-summary flag set.  
  --email-to (email address) sends email to that address
  rather than default $USER@fnal.gov 

- #7020 --mail_always doesnt work from within DAGS, fixed

- #7113 put $JOBSUBPARENTJOBID in environment for DAGS generated
  by dagNabbit.py and jobsub_tools.jobusb


v1_3_4 10/2/14
======================================================
- #7104  error in jdf for DAG jobs
- #7096  minerva wrapper script sets up environment after executing user job



v1_3_3  9/30/14
============================================
- INC000000450028  OS=(some_architecture) in jobsub.ini overrides command
         line options.  Fixed.
- #6670  --drain flag
- #6886  removed default OS = SL5.  There is no default OS.  NB on gpsn01
         this will require that the desired_os setting and the os setting
         in jobsub.ini must agree or jobs will not start
- #6763  feeding -N negative number has unpredictable results, now raises
         an exception and exits
- #6956  make --help documentation for --tar_file_name  agree with what 
         actually happens
- #6848  fixed bug introduced with #6848, CDF DAGs were required to have 
         more than one job in them.  Now they can have just one.
- #6934  now have --memory --disk and --cpu flags which take integers and
         request worker nodes with this much memory or disk in MB or
         this number of cpus 
- #6790  JobsubJobId and JobsubParentJobId are now both in classad and
         jobs execution environment


v1_3_2_0               9/2/14
=====================================================

--maxConcurrent (x) runs x number of jobs concurrently of -N submitted.
  This is implemented in a DAG.

--INC000000435202 and related fixed. Since v1_3_1_1, jobsub has been
  redirecting stdout and stderr into the $TMP directory and then tailing
  it back out to limit the size of log files that came back from a job.
  Some users scripts thoughtfully clean up the $TMP directory, resulting
  in no stdout or stderr returing from job.  Also since v1_3_1_1, ifdh 
  is not set up in users jobs by default . Changing the default to set up
  ifdh at run time on a per-experiment basis can be done with the 
  'set_up_ifdh' setting in the jobsub_ini file like so:

  [mu2e]
  set_up_ifdh = True
 
--https://cdcvs.fnal.gov/redmine/issues/6789  when --dataset_definition
  is used to submit a SAM job,  SAM_DATASET, SAM_GROUP, SAM_PROJECT, SAM_USER
  and SAM_STATION are now defined in user environment of grid job


v1_3_1_4_rc3
============================================================
  --fixed typo which prevents --start --end --sections from working
  obviously should be part of test suite 


v1_3_1_4_rc2
=========================================================
- further implementation of ticket 6697

  --maxParallelSec generates the same -maxidle and -maxjobs settings for 
  condor_submit_dag as CafSubmit does 

  --start --end, and --sections generate the same section numbers as happens
  when used with CafSubmit

  --outLocation works the same as it does for CafSubmit, except the only
  copyback option is scp.  If no --outLocation is specified the job tries
  to go back to fcdficaf2.

  -- the $ variable as an input parameter gets changed to $CAF_SECTION 
  every place it gets used in the CDF wrapper script . If $ appears in 
  the --outLocation, it gets substituted as ${CAF_SECTION}-${CAF_JID}, 
  which appears to be the same behavior as CafSubmit

v1_3_1_4_rc1
============================================================
- partial implementation of ticket 6697

  All the input flags to CafSubmit now present for jobsub
  when GROUP=cdf.  Most of them are no-ops however.
 
  Input tar file is unwound by the wrapper script and the
  rest of the input arguments are executed in-line in the resulting
  directory tree

  CAF_SECTION, CAF_JOB_BEGIN_SECTION, CAF_JOB_END_SECTION,
  CAF_JID all present in execution environment.  CAF_JOB_BEGIN_SECTION
  is always 1 CAF_JOB_END_SECTION is how many jobs were submitted. This
  will be fixed later.

  at end of job, tarball named with CAF_SECTION is created
  and scp'ed out, --outLocation value used  when present,
  sent to fcdficaf2 if not used.

v1_3_1_3 7/18/14
===========================================================
- nowrapfile disabled per request of Grid Operations Group
- changes for jobsub_client v0.4:
    --tar_file_name and server generated krb5cc file 
      pointed to by $INPUT_TAR_DIR and $KRB5CCNAME env variables
    -- SAM_GROUP SAM_STATION SAM_DATASET SAM_PROJECT SAM_USER all
      can be passed in with -e option and have intended effect 
      in SAM dags ie 
 ifdh startProject  $SAM_PROJECT $SAM_STATION $SAM_DATASET $SAM_USER $SAM_GROUP
 NB you do not *have* to set these, should work as before if you do not

v1_3_1_2 7/2/14
================================================================
- bug 6586 SAM Dag files incorrectly call ifdh
- bug 6549 --append_condor_requirements doesnt (on GPSN01 on local batch)
- test suite improved



v1_3_1_1 6/6/14
===============================================================
- INC000000417210   -l +AccountingGroup = "group_highprio.minervapro" 
  generates incorrect condor jdf on gpsn01 - fixed
- Feature 5907 Limit size of output/error that users bring back
  jobsub.ini setting max_jobsub_log_size = 5000000 (5MB) . Log files
  will be truncated from the end back to this size.
- (no issue number) Seaquest bluearc mounts were changed from
  /seaquest/app and /seaquest/data to /e906/app and /e906/data
  on 5/15/14. Gcso had to  manually edit jobsub.ini files to
  reflect this, changed here so they don't have to any more. 




v1_3_1 5/30/14
===============================================================
- INC000000416076 jobsub picking the wrong $GROUP for experiments
  where gid name different than VOMS group name, fixed.



v1_3_0 4/24/14
=================

- ifdh commands from the wrapper shell are setup and run from a spawned 
  environment so as not to pollute users environment
- ifdh does not do a --force=cpn when the --use_gftp option is not used,
  it now trusts ifdh to do the right thing
- RITM0092874, jobsub requires $HOME to be set, fixed
- RITM0096739 minos_jobsub updated



v1_2x 3/20/14
==================================

- consider this a pre-release of v1_3, intended to be  fully 
    HA-jobsub-server compatible and more grid-aware and grid-compatible 
    when run on gpsn01

- SAM.begin and SAM.end jobs in DAGs prior to this release always ran 
    locally on the submit_node. This places an unnecessary  maintenance 
    burden on the HA-jobsub-server so these jobs now run where the rest 
    of the DAG runs as specified by input to jobsub

- bug fixes
    + SAM.begin and SAM.end jobs now get the entire environment and 
    condor attributes and requriements generated with -l --resource-provides 
    --append_condor_requirements etc
    + a bug searching for ifdh in the wn_ifdh_location list, where it 
    failed to stop after finding correct version from the list 
    has been fixed
    + more careful and complete usage of (my.attribute = target.some_attribute) 
    generation convention in generated condor job requirements

- new settings in jobsub.ini
    + always_run_on_grid - if set to True for submit_host has the same 
    effect as always using -g when submitting. Useful for submit_hosts 
    which do not have local condor pools
    + default_grid_site - if present for submit_host is the glidein entry 
    point that submission is sent to if no --site parameter specified.  
    Disabled if not present or set to False

v1_2v 3/13/14
================

- ups unsetup left a messy environment behind which confused subsequent 
  setups of jobsub_tools. Fixed
- bug fixes to reading jobsub.ini, now uses the same library as the jobsub
  server


    
v1_2u 3/6/14
==============
- RITM0076669 changed condor_rm wrapper behavior to exactly pass on
    parameters to gpsn01's condor_rm.  The wrapper was needed because
    of a condor bug where the parameter JOB_STOP_COUNT  was ignored,
    this has since been fixed.

- parsing of jobsub.ini file sometimes, but not always, interprets
    some_setting = True as some_setting = 'True', the string value
    where the boolean was intended causes initialization problems.
    this is fixed.

- New Environment Variable that can affect behavior:

    + $WN_IFDH_LOCATION - a list of possible setup scripts to be searched 
    for ifdh in the wrapper script.  The default is to search bluearc,
    then local ups, then oasis.opensciencegrid.org/fermilab.  
    export WN_IFDH_LOCATION='/cvmfs/novacvs.fnal.gov/externals/setup /cvmfs/oasis.opensciencegrid.org/$EXPERIMENT/externals/setup' 
    is an example of a setting that nova might want to use on the OSG to
    set up the particular version of ifdh (and the rest of thier software
    stack at the same time)




v1_2t 3/3/14
============
- Changes to jobsub.ini :
    + various changes to make sure wrap.sh files get transported off site
        if no shared bluearc mount is available
    + wn_ifdh_location is now a list of possible ifdh UPS directories, the
        jobsub wrapper script will test them until it finds an installation
        of ifdhc.  Useful for probing cvmfs locations until ifdh is found
    + jobsub.ini better commented, order of loading of sections documented

- New Environment Variables that can affect behavior:
    + $TRANSFER_INPUT_FILES enviroment variable, a comma seperated list, 
        can be used to transfer input files to remote sites.  For example,
        export TRANSFER_INPUT_FILES=file1.tar,file2.tar ; jobsub -g 
        --site=somewhere will land file1.tar and file2.tar in the jobs working
        directory on the remote site .
    + $TRANSFER_EXECUTABLE - set to true or false.  If true, the executable
        and the wrapfile both get shipped off to worker node and land in the
        working directory.  This is inefficient if the executable is on a 
        shared disk for the worker nodes and the submit node, default is 
        false for gpsn01 and true for HA client/server nodes such as
        fifebatch1.  Setting this to TRUE  is useful on gpsn01 for 
        submitting to OSG.
 
- INC000000405338 --use_gftp -f  not working for input from /pnfs, fixed


v1_2s 2/18/14
=============
- bug fixes revealed by user testing of v1_2r


v1_2r 2/12/14
============
- improved implementation of feature 5284  --resource-provides.  
  --resource-provides cvmfs=osg,fermilab now checks for a has_cvmfs
  entry in jobsub.ini and that osg or fermilab are allowed values.
  The condor job classad then gets an attribute +DESIRED_cvmfs="osg,fermilab"
  and a an appended requirement that DESIRED_cvmfs matches values in 
  a machine classad attribute called HAS_cvmfs.


v1_2q 2/6/14
============-
- partial implementation of feature 5284 --resource-provides, sets 
    classad attributes and requirements.  No checking against glideinWMS 
    settings yet so its (still) possible to generate a job that will 
    never start
- bug 5266   --use_gftp does a --force=cpn on some ifdhc calls 
- fix for INC000000403944 -L and -N used together are allowed.





v1_2p 1/14/14
=============
- fix for Bug #5132  --SITE option is now case insensitive
- fix for INC000000401664 jobsub finds python without direct path
    to it in command line
- fix for INC000000402330 use umask instead of chmod to control mode
   of output files delivered by ifdhc/CPN


v1_2o 12/19/13
===============
- moved code repository from svn to git users 'shouldnt' notice any difference
- bug fix for https://cdcvs.fnal.gov/redmine/issues/5041
- fix for RITM0079516 in v1_2m introduced a second bug, SAM_STATION had to be set for SAM Dags to work.  Now fixed.

v1_2n 12/3/13
===================
- a problem removing temporary files if user aliased 'rm' to 'rm -i' has been fixed
- RITM0080175 setup jobsub_tools noisy, fixed
- INC000000399880 jobsub not respecting CONDOR_TMP if reset, fixed

v1_2m 11/19/13
====================
- RITM0079516 if SAM_STATION environment variable is set, use it when creating a sam project
- more stuff moved to configuration via ini file 


v1_2l 11/18/13
================
- bug fixes for handling jobsub.ini. 
- INC000000396421 selecting SL5 or SL6 on minos machines fixed

v1_2j 10/22/13
==============
- jobsub.ini file now does important configurations.  This is where you would add a new experiment instead of code changes.
  jobsub.ini is searched for first in $PWD, then $HOME, then $JOBSUB_TOOLS_DIR/bin


v1_2i 10/11/13
=============
--OS now accepts a comma seperated list  so '--OS=SL4,SL5,SL6,SL7' will run on any of
these if they are available




v1_2h 10/4/13
=============
bug fixes for
INC000000395648  -- Batch submission using dagNabbit.py is broken for csh-family
CHG000000006805  -- Deployment of SLF6 worker nodes on General Purpose Grid
also, a SAM project DAG will run only 2000 jobs at a time now

v1_2g_2 9/17/13
=================
INC000000394488  -L -N and --no_log_buffer play together correctly now

v1_2g_1 9/12/13
===================
bug fix: jobs sent off_site sometimes filled /tmp directory with cruft

v1_2g 9/11/13
====================
bug fix:  problem with -c option fixed

v1_2f 8/30/13
====================
bug fixes, 
	--site A,B,C now works properly to send jobs to OSG sites A, B, or C
	--parrot files were being generated in $CONDOR_TMP unnecessarily

v1_2e 8/14/13
=============================================
changed help on -c --append_condor_requirements, added 2 new ones
from the help:
    -c REQUIREMENTS, --append_condor_requirements=REQUIREMENTS
                        append condor requirements
    --overwrite_condor_requirements=OVERWRITEREQUIREMENTS
                        overwrite default condor requirements with supplied
                        requirements
    --override=OVERRIDE
                        override some other value: --override 'requirements'
                        'gack==TRUE' would produce the same condor command
                        file as --overwrite_condor_requirements 'gack==TRUE'
                        if you want to use this option, test it first with -n
                        to see what you get as output


v1_2d 8/8/13
=========================================
- fixes bug where jobs sent to local cluster could end up at SMU
- sends jobs to coupp experiments entry points


v1_2b 6/6/13
========================================
- Message of the Day and Downtime announcements
- sources condor setup scripts to set LD_LIBRARY_PATH on submit node

v1_2 5/15/13
========================================
rc5 retagged as v1_2 final


v1_2_rc5 final(?) v1_2 release candidate
========================================
- fix of minor bugs reported in v1_2_rc4



v1_2_rc4 final(?) v1_2 release candidate
========================================
- fix of nova environment setup
- fix of ifdh cp incantation
- fixes to test suite
- moved $CONDOR_TMP for argoneut minerva lbne uboone nova mu2e from /experiment/app to /experiment/data


v1_2_rc3 (release candidate 3)
===============================
- tarball support
  see https://cdcvs.fnal.gov/redmine/projects/ifront/wiki/UsingJobSub#tarball-support
  new options that support this:

    --input_tar_dir=INPUT_TAR_DIR
                        create self extracting tarball from contents of
                        INPUT_TAR_DIR.  This tarball will be run on the worker
                        node with arguments you give to your_script
    --tar_file_name=TAR_FILE_NAME
                        name of tarball to submit, created from
                        --input_tar_dir if specified
    --overwrite_tar_file
                        overwrite TAR_FILE_NAME when creating tarfile using
                        --input_tar_dir

- offsite support using --site flag to steer to remote sites
  see https://cdcvs.fnal.gov/redmine/projects/ifront/wiki/UsingJobSub#Using-jobsub-to-submit-to-remote-sites
- show_entrypoints command, see which remote sites are up/available

- group_q (experiment) command
- fixed typo in -t option for nova users
- restored throttled condor_rm , it had been removed accidentally

v1_1u 3/19/13
=============================================================
-fix of chmod bug for copying output on v1_1t



v1_1t 3/14/13
==============================================================

-changes behavior of -d flag so that multiple copies out are wrapped
with one CPN lock, similar to -f behavior as of v1_1s

-fixed unit tests broken by v1_1s code changes

v1_1s 3/13/13
=============================================================
- changed behavior of -f flag when used to copy in multiple files
previously, each file specified with -f was wrapped with its
own CPN locks. Starting with this version, a CPN lock will be
taken out, all the files copied in, and then the CPN lock will
be released.

v1_1r 3/8/13
=============================================================
-changed ifdh file transfers to use current ifdh instead of
hard coded v1_0_2 ifdh used in jobsub v1_1q .  This behavior
can be overridden by using environment variable IFDH_VERSION
with the -e flag, ie to use ifdh v1_0_3:
export IFDH_VERSION=v1_0_3
jobsub -e IFDH_VERSION (the rest of the command)

- fixed problems with unit tests and integration tests giving
false positives

- added sanity check for -e flag, it will complain now if you
do jobsub -d FOO without setting $FOO first

-updated OSG_WN_TMP to have same value as TMP,TMPDIR,TEMP,and  
$_CONDOR_SCRATCH_DIR at beginning of job execution on FNAL Grid. 



v1_1q 2/28/13
==========================================================
-replaced cpn and gridftp file transfers with ifdh cp commands
which default correctly to underlying cpn or gridftp.  All transfer
in with -f option defaults to cpn for speed.

-improved documentation output with -h flag

-updated TMP,TMPDIR,TEMP to have same value of $_CONDOR_SCRATCH_DIR 
at beginning of job execution on FNAL Grid. 

v1_1p 2/20/13
==========================================================
-added ifdh log monitoring for job start, job end, file transfers 
 in and out with -f and -d flags
-minor bug fixes exposed by improved test suite



v1_1o  2/18/13
==========================================================
another gridftp fix, bug in cpn style locking mechanism allowed
gridftp servers to become overloaded

v1_1n 2/13/13
==========================================================
-gridftp fix, command to transfer output data back got removed
in 1_1k by svn misuse


v1_1k 1/25/13
=========================================================
-fixed a bug for minerva, now picks up the $CMTCONFIG env variable
 v1_1j release did not pick up this change due to svn misuse


v1_1j 1/22/13
=========================================================
-fixed a bug for minerva, now picks up the $CMTCONFIG env variable
-changed the wrapped condor commands to use ssh -akx instead of ssh -ak




v1_1i 1/19/13
==================================================
- changed default behavior of -L /path/to/logfile behavior
  now write logfile to local disk on worker node, then
  gridftp or cpn it back to specified location.
  This behavior can be overridden with --no_log_buffer flag

v1_1h 12/19/12
==================================================
-changed path to ifdhc ups product

v1_1g 12/11/12
==================================================
-removed minerva_q, it behaved differently than what they expected

v1_1f 11/19/12
=============================================
- more dag file fixing
- changed order of PATH for wrapped, metered condor commands (condor_q etc)

v1_1e 11/9/12
==========================================
- fixed a bug where dag files were not submitted properly


v1_1d 11/8/12
===============================================
-fixed a problem with -T option, test queue works now
-fixed URI for samweb which changed recently

v1_1c 10/18/12
===================================================
- fixed a typo in csh environment for nova
- made jobsub aware of mars gftp servers


v1_1b 10/17/12
=====================================================
-fixed a nova configuration bug for nova
-changed -L option to record stderr as well as stdin output


v1_1a 9/28/12
===================
- fixed a bug where -e was quoting vars when it should not ie
export FOO=BAR
jobsub -e FOO should result in $FOO == BAR being true on worker node, 
 but it was actually  $FOO="BAR" being true.  fixed.

v1_1 9/27/12
==================
- increased jobleaseduration to 6 hours
- fixed a bug where -opportunistic was interpreted as 
   --outputfile=='pportunistic'


v1_0  9/14/12
===================
- first production release
- documentation subdirectory, improved jobsub -h behavior
- changed default mail behavior, default is to send mail on error

v0_7  8/31/12
====================
- bugfix, jobsub [jobsub_options] script [script_options] was incorrectly
  grabbing any [script_option] that began with a dash and making it 
  a [jobsub_option]
- documentation fixes
- changed default Joblease_duration to 1 hr from 20 minutes


v0_5 8/6/12
=====================
- Submission to SMU for Nova works

v0_4  7/19/12
======================
- works correctly with csh or sh
- changed underlying option handling to use optparse package

v0_3  6/7/12
======================
-fixes to dagNabbit.py
-fixed: return value of condor job becomes return value of jobsub
-request_robot_cert accomodates new behavior of kxlist -p

v0_2  
======================
Unit tests improved.

v0_1  5/17/2012
===========================
First UPS/UPD version, KITS product is jobsub_tools, i.e.  setup jobsub_tools

Includes unit test, to run:
sh $JOBSUB_TOOLS_DIR/test/Run_Unit_Tests.sh

includes functionality test, to submit jobs (and expected output):
$JOBSUB_TOOLS_DIR/test/Run_All_Tests.sh 
testing a grid job
/nova/data/condor-tmp/dbox/test_grid_env.sh_20120806_142211_26319_1.cmd
submitting....
Submitting job(s).
Logging submit event(s).
1 job(s) submitted to cluster 3796504.
testing a local job
/nova/data/condor-tmp/dbox/test_local_env.sh_20120806_142211_26328_1.cmd
submitting....
Submitting job(s).
Logging submit event(s).
1 job(s) submitted to cluster 3796505.

---------------------------------------------------------
condor_q dbox will show the progress of your jobs just 
submitted to gpsn01.fnal.gov
ifront_q will show the state of everyones jobs on this node
---------------------------------------------------------







 













