#!/usr/bin/env python

import os
import sys
import stat
import commands
import re
import datetime
import time
from JobsubConfigParser import JobsubConfigParser
import xml.etree.ElementTree as ET

docString = """
 $Id$
"""
manual = """

Server input options: --maxConcurrent  maximum number of DAG nodes that can be run simultaneously

USER_SCRIPT FORMAT:

jobsub_submit_dag generates and optionally runs a condor 
DAG (directed acyclic graph) of condor jobs.  For illustration, suppose
that you have 5 jobs A,B,C,D,E, that you want to run using condor. 
Job B requires A to run first, C and D require the output form B, 
and E requires the input from C and D.
A graphic representation would be:

                      A
                      |
                      B
                     / \\
                    C   D
                     \ /
                      E

Job A can be submitted to the batch system 
using the command 
jobsub_submit file://jobA.sh, job B by jobsub_submit file://jobB.sh, etc.


The input file for the DAG generator in this example would look like this:

<serial>
jobsub_submit file://jobA.sh
jobsub_submit file://jobB.sh
</serial>
<parallel>
jobsub_submit file://jobC.sh
jobsub_submit file://jobD.sh
</parallel>
<serial>
jobsub_submit file://jobE.sh
</serial>

If this input file is saved as 'user_script', the command to 
generate and submit a DAG would be

jobsub_submit_dag [Client Options] [Server Options] file://user_script 
"""
usage = """
usage: %s -i input_file [-o output_dag] [-h(elp)] [-s(ubmit)] [--maxConcurrent  max_concurrent_jobs ]

for detailed instructions on how to use:
%s -manual | less
"""
cmd_file_dummy = """
universe      = vanilla
executable    = %s/returnOK_%s.sh
output     = %s/returnOK_%s.out
error      = %s/returnOK_%s.err
log        = %s/returnOK_%s.log
environment   = PROCESS=$(Process);CONDOR_TMP=%s;CONDOR_EXEC=%s
rank       = Mips / 2 + Memory
notification  = Error
requirements  = ((target.Arch=="X86_64") || (target.Arch=="INTEL"))
+RUN_ON_HEADNODE = TRUE

queue
"""
wrap_file_dummy = """#!/bin/sh
#
exit 0
"""


class L(list):
    """
    A subclass of list that can accept additional attributes.
    Should be able to be used just like a regular list.

    The problem:
    a = [1, 2, 4, 8]
    a.x = "Hey!" # AttributeError: 'list' object has no attribute 'x'

    The solution:
    a = L(1, 2, 4, 8)
    a.x = "Hey!"
    print a       # [1, 2, 4, 8]
    print a.x     # "Hey!"
    print len(a)  # 4

    You can also do these:
    a = L( 1, 2, 4, 8 , x="Hey!" )                 # [1, 2, 4, 8]
    a = L( 1, 2, 4, 8 )( x="Hey!" )                # [1, 2, 4, 8]
    a = L( [1, 2, 4, 8] , x="Hey!" )               # [1, 2, 4, 8]
    a = L( {1, 2, 4, 8} , x="Hey!" )               # [1, 2, 4, 8]
    a = L( [2 ** b for b in range(4)] , x="Hey!" ) # [1, 2, 4, 8]
    a = L( (2 ** b for b in range(4)) , x="Hey!" ) # [1, 2, 4, 8]
    a = L( 2 ** b for b in range(4) )( x="Hey!" )  # [1, 2, 4, 8]
    a = L( 2 )                                     # [2]
    shamelessy lifted from:
    https://code.activestate.com/recipes/579103-python-addset-attributes-to-list/
    """

    def __new__(self, *args, **kwargs):
        return super(L, self).__new__(self, args, kwargs)

    def __init__(self, *args, **kwargs):
        if len(args) == 1 and hasattr(args[0], '__iter__'):
            list.__init__(self, args[0])
        else:
            list.__init__(self, args)
        self.__dict__.update(kwargs)

    def __call__(self, **kwargs):
        self.__dict__.update(kwargs)
        return self


class DagParser(object):

    def __init__(self):

        self.jobList = []
        self.jobNameList = []
        self.macroList = []
        self.beginJobList = []
        self.finishJobList = []

        self.jobDict = {}
        self.jobNameDict = {}
        self.macroDict = {}
        self.beginJobDict = {}
        self.finishJobDict = {}

        self.processingMacros = False
        self.processingSerial = False
        self.processingParallel = False
        self.processingBeginJob = False
        self.processingFinishJob = False
        self.redundancy = 0
        self.condor_tmp = os.environ.get("CONDOR_TMP")
        self.jnum = 1
        self.pnum = 1
        self.snum = 1
        self.nodeDict = {}
        self.dagDict = {}
        self.pcList = []

#######################################################################

    def startSerial(self, s):

        s = s.lower()
        if s.find("<serial>") >= 0:
            self.processingSerial = True
            return True
        return False

    def endSerial(self, s):

        s = s.lower()
        if s.find("</serial>") >= 0:
            self.processingSerial = False
            return True
        return False

#######################################################################

    def startParallel(self, s):

        s = s.lower()
        if s.find("<parallel>") >= 0:
            self.processingParallel = True
            return True
        return False

    def endParallel(self, s):

        s = s.lower()
        if s.find("</parallel>") >= 0:
            self.processingParallel = False
            return True
        return False

#######################################################################

    def startBeginJob(self, s):
        s = s.lower()
        if s.find("<beginjob>") >= 0:
            self.processingBeginJob = True
            return True
        return False

    def endBeginJob(self, s):
        s = s.lower()
        if s.find("</beginjob>") >= 0:
            self.processingBeginJob = False
            return True
        return False

    def isInBeginJob(self, s):
        if self.startBeginJob(s):
            self.processingBeginJob = True
        return self.processingBeginJob

    def processBeginJob(self, line):
        if self.endBeginJob(line):
            self.processingBeginJob = False
        else:
            line = line.strip()
            self.beginJobList.append(line)
            # print "self.beginJobList=",self.beginJobList

#######################################################################

    def startFinishJob(self, s):
        s = s.lower()
        if s.find("<finishjob>") >= 0:
            self.processingFinishJob = True
            return True
        return False

    def endFinishJob(self, s):
        s = s.lower()
        if s.find("</finishjob>") >= 0:
            self.processingFinishJob = False
            return True
        return False

    def isInFinishJob(self, s):
        if self.startFinishJob(s):
            self.processingFinishJob = True
        return self.processingFinishJob

    def processFinishJob(self, line):
        if self.endFinishJob(line):
            self.processingFinishJob = False
            self.finishJobList.append("mailer.py ")
        else:
            line = line.strip()
            self.finishJobList.append(line)
#######################################################################

    def startMacros(self, s):
        s = s.lower()
        if s.find("<macros>") >= 0:
            self.processingMacros = True
            return True
        return False

    def endMacros(self, s):
        s = s.lower()
        if s.find("</macros>") >= 0:
            self.processingMacros = False
            return True
        return False

    def isInMacros(self, s):
        if self.startMacros(s):
            self.processingMacros = True
        return self.processingMacros

    def processMacro(self, line):
        # print "processMacro input=",line
        if self.endMacros(line):
            self.processingMacros = False
        elif line.find("=") >= 0:
            [a, b] = line.split("=")
            a = a.strip()
            b = b.strip()
            self.macroList.append(a)
            self.macroDict[a] = b
            if (b.find("`") == 0):
                if (b.find("`", 1) == (len(b) - 1)):
                    cmd = b[1:len(b) - 1]
                    (retVal, val) = commands.getstatusoutput(cmd)
                    if retVal == 0:
                        self.macroDict[a] = val

#######################################################################

    def nameNode(self, elem):
        #global snum,pnum,jnum, nodeDict
        if elem.attrib.has_key('name'):
            self.nodeDict[elem.attrib['name']] = elem
            return
        if elem.tag == 'serial':
            elem.attrib['name'] = 'Serial_%s' % (self.snum)
            self.snum += 1
        if elem.tag == 'parallel':
            elem.attrib['name'] = 'Parallel_%s' % (self.pnum)
            self.pnum += 1
        if elem.tag == 'job':
            elem.attrib['name'] = 'Job_%s' % (self.jnum)
            self.jnum += 1
        if elem.tag == 'dag':
            elem.attrib['name'] = 'dag'
        self.nodeDict[elem.attrib['name']] = elem

    def labelTree(self, elem):
        self.nameNode(elem)
        l = list(elem)
        if len(l):
            for i2 in range(0, len(l)):
                x = l[i2]
                self.nameNode(x)
                l2 = list(x)
                if len(l2):
                    self.labelTree(x)

    def makeJobLists(self, elem):
        l = list(elem)
        if len(l):
            jlist = L()
            jlist.tag = elem.tag
            for x in l:
                jlist.append(x.attrib['name'])
                l2 = list(x)
                if len(l2):
                    self.makeJobLists(x)

        if len(jlist):
            jobs = " ".join(jlist)
            elem.attrib['joblist'] = jobs
            self.dagDict[elem.attrib['name']] = jlist

    def expand(self, jlist):
        for n, i in enumerate(jlist):
            if self.dagDict.get(str(i)):
                jlist[n] = self.dagDict.get(str(i))
        for n, i in enumerate(jlist):
            if isinstance(i, list):
                jlist[n] = self.expand(i)
        return jlist

    def getJobs(self, jlist, ndx=0):
        tag = getattr(jlist, 'tag', False)
        if tag == 'parallel':
            j = ''
            for j1 in jlist:
                j += self.getJobs(j1, ndx)
                j += ' '
            return j
        elif tag == 'serial':
            return self.getJobs(jlist[ndx], ndx)
        else:
            return jlist

    def generateParentChildList(self, jlist):
        par_or_ser = getattr(jlist, 'tag', False)
        if par_or_ser:
            for n, i in enumerate(jlist):

                if n == 0:
                    self.generateParentChildList(jlist[n])

                elif n > 0:

                    p = self.getJobs(jlist[n - 1], ndx=-1)
                    self.generateParentChildList(jlist[n - 1])

                    c = self.getJobs(jlist[n], ndx=0)
                    self.generateParentChildList(jlist[n])

                    if par_or_ser == 'serial':
                        pc = "parent %s child %s" % (p, c)
                        if pc not in self.pcList:
                            self.pcList.append(pc)

    def printJobRelationships(self, outFile):
        with open(outFile, "a") as f:
            for line in self.pcList:
                f.write("%s\n" % line)
        f.close()

    def reportState(self):
        print "processingSerial:%s processingParallel:%s" %\
            (self.processingSerial, self.processingParallel)
        print self.jobList
        print self.jobDict

    def digestInputFile(self, args):
        # strip out comments starting with '#'
        infile = args.inputFile
        xmlfile = "%s.xml" % infile
        r = re.compile("#.*")
        plist = []
        if len(sys.argv) > 1:
            f = open(infile, "r")
            x = open(xmlfile, "w")
            x.write("<dag>\n")
            i = 0
            j = 0
            for line in f:
                line = line.strip()
                line = r.sub('', line)
                line = line.replace('jobsub_submit', 'jobsub')
                line = line.replace('jobsub ', 'jobsub -n ')
                # print "input line " , line
                if 'jobsub ' not in line and len(line) > 0:
                    x.write("%s\n" % line)

                if self.startSerial(line):
                    pass
                elif self.endSerial(line):
                    pass
                elif self.startParallel(line):
                    plist = []
                elif self.endParallel(line):
                    self.jobList.append(plist)
                elif self.isInMacros(line):
                    self.processMacro(line)
                elif self.isInBeginJob(line):
                    self.processBeginJob(line)
                elif self.isInFinishJob(line):
                    self.processFinishJob(line)

                elif len(line) > 0:
                    for mac in self.macroList:
                        line = line.replace(mac, self.macroDict[mac])
                    val = ""
                    j += 1
                    os.environ['JOBSUBJOBSECTION'] = "%s" % j
                    passedArgs = ' '.join(args.passedArgs)
                    passedArgs = """ -e JOBSUBJOBSECTION --lines '+JobsubJobSection=\\\"%s\\\"' %s """ % (
                        j, passedArgs)
                    repVal = "jobsub %s " % passedArgs
                    line = line.replace("jobsub ", repVal)
                    (retVal, val) = commands.getstatusoutput(line)
                    if retVal:
                        print "error processing command %s" % line
                        print val
                        sys.exit(1)
                    else:
                        condor_cmd = ''
                        condor_cmd_list = []
                        biglist = val.split()
                        ncmds = 0
                        i = 0
                        for word in biglist:
                            if word.find(".cmd") >= 0 and word not in condor_cmd_list:
                                ncmds = ncmds + 1
                                condor_cmd = word
                                jobName = "Jb_%d_%d" % (j, i)
                                x.write("""<job name="%s" cmd="%s" />\n""" %
                                        (jobName, condor_cmd))
                                self.jobNameList.append(jobName)
                                self.jobDict[condor_cmd] = jobName
                                self.jobNameDict[jobName] = condor_cmd
                                condor_cmd_list.append(condor_cmd)
                                i += 1
                        if self.processingSerial:
                            self.jobList.append(tuple(condor_cmd_list))
                        if self.processingParallel:
                            plist.append(tuple(condor_cmd_list))
                        if (self.redundancy != 0 and self.redundancy != len(condor_cmd_list)):
                            print "ERROR: different number of '.cmd' files detected"
                            print "between jobs in input file! This will generate"
                            print "an incorrect DAG!  aborting......"
                            # sys.exit(-1)
                            self.redundancy = len(condor_cmd_list)
                        else:
                            self.redundancy = len(condor_cmd_list)

                        # reportState()
            x.write('</dag>\n')
            x.close()
            tree = ET.parse(xmlfile)
            root = tree.getroot()
            self.labelTree(root)
            self. makeJobLists(root)

            cntr = 0
            for line in self.beginJobList:
                for mac in self.macroList:
                    line = line.replace(mac, self.macroDict[mac])
                    # print line
                    self.beginJobList[cntr] = line
                cntr += 1
            cntr = 0
            for line in self.finishJobList:
                for mac in self.macroList:
                    line = line.replace(mac, self.macroDict[mac])
                    # print line
                    self.finishJobList[cntr] = line
                cntr += 1

    def getJobName(self, jlist, i, j=0):

        if isinstance(jlist[i], tuple):
            retval = self.jobDict[jlist[i][j]]

        elif isinstance(jlist[i], list):
            retval = ""
            for l in jlist[i]:
                retval = retval + " " + self.getJobName(l, 0, j)
        else:

            retval = self.jobDict[jlist[j]]

        return retval

    def generateDependencies(self, outputFile, jlist):
        f = open(outputFile, "a")
        jend = len(jlist)
        i = 0

        if len(self.beginJobList) > 0:
            j = 0
            while(j < self.redundancy):
                l = "parent JOB_BEGIN child %s\n" % self.getJobName(
                    jlist, i, j)
                f.write(l)
                j += 1

        while (i < jend - 1):
            j = 0
            while(j < self.redundancy):
                l = "parent %s child %s\n" %\
                    (self.getJobName(jlist, i, j), self.getJobName(jlist, i + 1, j))
                f.write(l)
                j += 1
            i += 1

        if len(self.finishJobList) > 0:
            j = 0

            while(j < self.redundancy):
                l = "parent %s child JOB_FINISH\n" % self.getJobName(
                    jlist, i, j)
                f.write(l)
                j += 1

        f.close()

    def writeDummyCmdFile(self):

        condor_tmp = os.environ.get("CONDOR_TMP")
        if condor_tmp is None:
            print "ERROR, CONDOR_TMP env variable needs to be set!"
            sys.exit(-1)

        condor_exec = os.environ.get("CONDOR_EXEC")
        if condor_exec is None:
            print "ERROR, CONDOR_EXEC env variable needs to be set!"
            sys.exit(-1)

        now = datetime.datetime.now()
        filebase = "%s%02d%02d_%02d%02d%02d" % (now.year, now.month, now.day,
                                                now.hour, now.minute, now.second)
        cmd_file_name = "%s/dummy%s.cmd" % (condor_tmp, filebase)
        wrap_file_name = "%s/returnOK_%s.sh" % (condor_exec, filebase)
        cmd_file = cmd_file_dummy % (condor_exec, filebase, condor_tmp, filebase, condor_tmp,
                                     filebase, condor_tmp, filebase, condor_tmp, condor_exec)

        f = open(cmd_file_name, "w")
        f.write(cmd_file)
        f.close()
        f = open(wrap_file_name, "w")
        f.write(wrap_file_dummy)
        f.close()
        os.chmod(wrap_file_name, stat.S_IRWXU | stat.S_IRGRP |
                 stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)
        return cmd_file_name

    def generateDag(self, outputFile=None):

        f = open(outputFile, "w")
        l = "DOT %s.dot UPDATE\n" % outputFile
        f.write(l)

        if len(self.beginJobList) > 0:

            l = "JOB JOB_BEGIN %s\n" % self.writeDummyCmdFile()
            f.write(l)

        # for n in self.jobNameList:
        #    l = "JOB " + n + " "+ self.jobNameDict[n]+"\n"
        #    f.write(l)

        for k in sorted(self.nodeDict.keys()):
            e = self.nodeDict[k]
            if e.tag == 'job':
                f.write("JOB %s %s\n" % (k, e.attrib['cmd']))

        if len(self.finishJobList) > 0:
            time.sleep(1)
            l = "JOB JOB_FINISH %s \n" % self.writeDummyCmdFile()
            f.write(l)

        if len(self.beginJobList) > 0:
            l = "SCRIPT PRE JOB_BEGIN %s \n" % self.beginJobList[1]
            f.write(l)
        if len(self.finishJobList) > 0:
            l = "SCRIPT POST JOB_FINISH %s \n" % self.finishJobList[1]
            f.write(l)

        f.close()
        # self.generateDependencies(outputFile,self.jobList)
        jobList = L(self.dagDict.get('dag'), tag='serial')
        self.expand(jobList)
        self.generateParentChildList(jobList)
        self.printJobRelationships(outputFile)


# this should really use optparse but too many of the input
# options are malformed for optparse  - not enough dashes etc
# also --subgroups has to go both to this programs input and on to jobsub
#
# parse out the ones we intend to use and pass the rest on to jobsub
#
class ArgParser(object):

    def __init__(self, cfp):
        cfp.findConfigFile()
        self.inputFile = None
        self.outputFile = ""
        self.runDag = False
        self.viewDag = False
        self.maxJobs = 0
        self.passedArgs = None
        self.submitHost = os.environ.get("SUBMIT_HOST")
        self.condorSetup = cfp.get(self.submitHost, "condor_setup_cmd")
        self.group = os.environ.get("GROUP")
        self.subgroup = None
        self.passedArgs = []
        allowed = cfp.supportedGroups()
        if len(self.condorSetup) > 0 and self.condorSetup.find(';') < 0:
            self.condorSetup = self.condorSetup + ";"

        if self.group not in allowed:
            print "ERROR do not run this script as member of group %s" % self.group
            print "export GROUP=one of %s and try again" % allowed
            sys.exit(-1)

        i = 0
        args = sys.argv
        passedArgs = []
        argLen = len(sys.argv)

        while i < argLen:
            arg = args[i]
            if arg in ["--h", "-h", "--help", "-help"]:
                self.printHelp()
            elif arg in ["-man", "-manual"]:
                self.printManual()
            elif arg in ["--inputFile", "-input_file", "-i"]:
                if os.path.isfile(args[i + 1]):
                    self.inputFile = args[i + 1]
                    i += 1
            elif arg in ["--outputFile", "-output_file", "-o"]:
                self.outputFile = args[i + 1]
                i += 1
            elif arg in ["--maxConcurrent", "--maxRunning", "-max_running", "-m"]:
                self.maxJobs = int(args[i + 1])
                i += 1
            elif arg in ["--submit", "-submit", "-s"]:
                self.runDag = True
            elif arg == "--subgroup":
                self.subgroup = args[i + 1]
                self.passedArgs.append("--subgroup")
                self.passedArgs.append(self.subgroup)
                i += 1

            elif i > 0:
                self.passedArgs.append(arg)
            i += 1

        if self.inputFile is None:
            i = 0
            fileOpts = ['-L', '--log_file',
                        '--tar_file_name', '-f', '-i', '-t']
            for arg in self.passedArgs:
                if os.path.isfile(arg):
                    if (i == 0) or ((i > 0) and (self.passedArgs[i - 1] not in fileOpts)):
                        self.inputFile = self.passedArgs[i]
                        del self.passedArgs[i]
                        break
                i += 1

        if self.outputFile == "":
            cmd = """date +%Y%m%d_%H%M%S"""
            # commands=JobUtils()
            (retVal, val) = commands.getstatusoutput(cmd)
            if retVal == 0:
                now = val.rstrip()
                condor_tmp = os.environ.get("CONDOR_TMP")
                home = os.environ.get("HOME")
                if condor_tmp == "" or condor_tmp == None:
                    self.outputFile = home + "/submit.%s.dag" % now
                else:
                    self.outputFile = condor_tmp + "/submit.%s.dag" % now
                # print "generated DAG saved as ", self.outputFile
            else:
                sys.stderr.write("error executing %s\n ") % cmd
                sys.stderr.write("%s\n ") % val
                sys.exit(1)

    def report(self):
        print "====================================="
        print "inputFile = ", self.inputFile
        print "outputFile = ", self.outputFile
        print "runDag =", self.runDag
        print "maxJobs =", self.maxJobs

    def printHelp(self):
        h = os.path.basename(sys.argv[0])
        helpFile = usage % (h, h)
        print helpFile
        sys.exit(0)

    def printManual(self):
        #m = os.path.basename(sys.argv[0])
        #df = """date +%Y%m%d_%H%M%S_%N"""
        #manFile = manual 
        print manual
        sys.exit(0)


class JobRunner(object):

    def __init__(self):
        pass

    def doSubmit(self, args=None):
        cmd = ""
        # commands=JobUtils()
        (retVal, host) = commands.getstatusoutput("uname -n")
        ups_shell = os.environ.get("UPS_SHELL")
        if ups_shell is None:
            ups_shell = "sh"

        if host == args.submitHost:
            cmd = """condor_submit_dag -dont_suppress_notification  """
        else:
            cmd = """ssh %s "condor_submit_dag -dont_suppress_notification """\
                % (args.submitHost)
        if args.maxJobs > 0:
            cmd = cmd + " -maxjobs %d " % args.maxJobs
        usr = os.environ.get("USER")
        grp = os.environ.get("GROUP")

        subgroup = None
        if args is not None:
            subgroup = args.subgroup

        cmd += """ -append "+Owner=\\"%s\\"" """ % usr
        if subgroup:
            cmd += """-append "+AccountingGroup=\\"group_%s.%s.%s\\"" """ %\
                (grp, subgroup, usr)
        else:
            cmd += """-append "+AccountingGroup=\\"group_%s.%s\\"" """ %\
                (grp, usr)
        cmd += """ -append "+JobsubJobId=\\"\$(Cluster).\$(Process)@%s\\"" """ % (
            args.submitHost)
        cmd += args.outputFile
        if host != args.submitHost:
            cmd += ' "'
        print "executing %s " % cmd
        (retVal, val) = commands.getstatusoutput(cmd)
        if retVal:
            print "ERROR executing %s" % cmd
            print val
            retVal = retVal % 256
            if retVal == 0:
                retVal = 1
            sys.exit(retVal)
        print val


if __name__ == '__main__':
    c = JobsubConfigParser()
    args = ArgParser(c)
    d = DagParser()
    d.digestInputFile(args)
    d.generateDag(args.outputFile)
    if args.runDag:
        j = JobRunner()
        j.doSubmit(args)
