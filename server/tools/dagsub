#!/usr/bin/env python

import os
import sys
import stat
import commands
import re
import datetime
import time
from JobsubConfigParser import JobsubConfigParser
import xml.etree.ElementTree as ET

docString = """
 $Id$
"""
manual = """
INTRODUCTION
============
%s is a script which generates and optionally runs a condor 
DAG (directed acyclic graph) of condor jobs.  For illustration, suppose
that you have 5 jobs A,B,C,D,E, that you want to run using condor. 
Job B requires A to run first, C and D require the output form B, 
and E requires the input from C and D.
A graphic representation would be:

                      A
                      |
                      B
                     / \\
                    C   D
                     \ /
                      E

Further suppose for illustration that job A is submitted to condor 
using the command jobsub -g jobA.sh, job B by jobsub -g jobB.sh, etc.
The jobsub script has a '-n' option, which generates but does not submit
the condor command file. When this option is added, the condor command file
is sent to stdout.  My output for the command 'jobsub -g -n jobA.sh' was:

 /minerva/app/users/condor-tmp/dbox/jobA.sh_20110830_105651_1.cmd

THIS SCRIPT REQUIRES THAT ONE OR MORE CONDOR COMMAND FILES OF THE FORM
/path/to/my/command/file/runMyJob.cmd  are sent to stdout, this
is captured and put in the condor DAG command file

INPUT FILE BASICS
=================
The input file for the DAG generator in this example would look like this:
<serial>
jobsub -g -n jobA.sh
jobsub -g -n jobB.sh
</serial>
<parallel>
jobsub -g -n jobC.sh
jobsub -g -n jobD.sh
</parallel>
<serial>
jobsub -g -n jobE.sh
</serial>

INPUT FILE MACROS
============
It is common for scripts to have inputs to 'sweep' through a set of parameters.
Let us suppose that the jobA.sh et al accept input paramters like so:

./jobA.sh -firstRun (some_number) -lastRun (some_bigger_number) -title (something arbitrary but meaningful to user)

The 'macros' section of the input file handles this requirement like so:

<macros>
$first = 1
$last = 100
$formatted_date=`%s`
$current_directory  = `pwd`
$whatever = 'some string that has significance elsewhere'
</macros>
<serial>
jobsub -g -n $current_directory/jobA.sh -firstRun $first -lastRun $last -title $whatever
jobsub -g -n $current_directory/jobB.sh -firstRun $first -lastRun $last -title $whatever
</serial>
<parallel>
jobsub -g -n jobC.sh -firstRun $first -lastRun $last -title $whatever
jobsub -g -n jobD.sh -firstRun $first -lastRun $last -title $whatever
</parallel>
<serial>
jobsub -g -n jobE.sh -firstRun $first -lastRun $last -title $whatever
</serial>

IT IS IMPORTANT that EACH COMMAND GENERATE THE SAME NUMBER OF CONDOR CMD
FILES, or the resultant dag will be incorrect.

BEGINJOB AND FINISHJOB SCRIPTS
=============================

Users have the option of running a pre-staging script prior to thier dag
and a cleanup script afterwards using the <beginjob> and <finishjob> tags.
The scripts specified this way run on the submission machine and not on the 
condor worker nodes as the serial and parallel jobs do.

An example script using these tags follows:

<macros>
$project_name = 'project_3'
$dataset_def = 'dataset_5'
$first = 1
$last = 100
$whatever  = Joes Third Attempt At Running This
</macros>
<beginjob>
startSAMProject.sh $dataset_def $project_name
</beginjob>
<serial>
jobsub -g -n jobA.sh -project_name $project_name
</serial><parallel>
jobsub -g -n jobC.sh -firstRun $first -lastRun $last -title $whatever
jobsub -g -n jobD.sh -firstRun $first -lastRun $last -title $whatever
</parallel>
<serial>
jobsub -g -n jobE.sh -firstRun $first -lastRun $last -title $whatever
</serial>
<finishjob>
clean_up_SAM_project.sh $project_name
</finishjob>


RUNNING A DAG
==============
%s -input_file (inputFile) -s will submit your generated DAG to condor.  The -m (pos_integer) 
flag will ensure that only (pos_integer) number of your jobs will run at the same time, which
is intended to prevent overwhelming shared resources such as databases.
"""
usage = """
usage: %s -i input_file [-o output_dag] [-h(elp)] [-s(ubmit)] [--maxConcurrent  max_concurrent_jobs ]

for detailed instructions on how to use:
%s -manual | less
"""
cmd_file_dummy = """
universe      = vanilla
executable    = returnOK_%s.sh
output     = returnOK_%s.out
error      = returnOK_%s.err
log        = returnOK_%s.log
environment   = PROCESS=$(Process)
rank       = Mips / 2 + Memory
notification  = Error
requirements  = ((target.Arch=="X86_64") || (target.Arch=="INTEL"))
+RUN_ON_HEADNODE = TRUE

queue
"""
wrap_file_dummy = """#!/bin/sh
#
exit 0
"""


class L(list):
    """
    A subclass of list that can accept additional attributes.
    Should be able to be used just like a regular list.

    The problem:
    a = [1, 2, 4, 8]
    a.x = "Hey!" # AttributeError: 'list' object has no attribute 'x'

    The solution:
    a = L(1, 2, 4, 8)
    a.x = "Hey!"
    print a       # [1, 2, 4, 8]
    print a.x     # "Hey!"
    print len(a)  # 4

    You can also do these:
    a = L( 1, 2, 4, 8 , x="Hey!" )                 # [1, 2, 4, 8]
    a = L( 1, 2, 4, 8 )( x="Hey!" )                # [1, 2, 4, 8]
    a = L( [1, 2, 4, 8] , x="Hey!" )               # [1, 2, 4, 8]
    a = L( {1, 2, 4, 8} , x="Hey!" )               # [1, 2, 4, 8]
    a = L( [2 ** b for b in range(4)] , x="Hey!" ) # [1, 2, 4, 8]
    a = L( (2 ** b for b in range(4)) , x="Hey!" ) # [1, 2, 4, 8]
    a = L( 2 ** b for b in range(4) )( x="Hey!" )  # [1, 2, 4, 8]
    a = L( 2 )                                     # [2]
    shamelessy lifted from:
    https://code.activestate.com/recipes/579103-python-addset-attributes-to-list/
    """

    def __new__(self, *args, **kwargs):
        return super(L, self).__new__(self, args, kwargs)

    def __init__(self, *args, **kwargs):
        if len(args) == 1 and hasattr(args[0], '__iter__'):
            list.__init__(self, args[0])
        else:
            list.__init__(self, args)
        self.__dict__.update(kwargs)

    def __call__(self, **kwargs):
        self.__dict__.update(kwargs)
        return self


class DagParser(object):

    def __init__(self):

        self.jobList = []
        self.jobNameList = []
        self.macroList = []
        self.beginJobList = []
        self.finishJobList = []

        self.jobDict = {}
        self.jobNameDict = {}
        self.macroDict = {}
        self.beginJobDict = {}
        self.finishJobDict = {}

        self.processingMacros = False
        self.processingSerial = False
        self.processingParallel = False
        self.processingBeginJob = False
        self.processingFinishJob = False
        self.redundancy = 0
        self.condor_tmp = os.environ.get("CONDOR_TMP")
        self.jnum = 1
        self.pnum = 1
        self.snum = 1
        self.nodeDict = {}
        self.dagDict = {}
        self.pcList = []

#######################################################################

    def startSerial(self, s):

        s = s.lower()
        if s.find("<serial>") >= 0:
            self.processingSerial = True
            return True
        return False

    def endSerial(self, s):

        s = s.lower()
        if s.find("</serial>") >= 0:
            self.processingSerial = False
            return True
        return False

#######################################################################

    def startParallel(self, s):

        s = s.lower()
        if s.find("<parallel>") >= 0:
            self.processingParallel = True
            return True
        return False

    def endParallel(self, s):

        s = s.lower()
        if s.find("</parallel>") >= 0:
            self.processingParallel = False
            return True
        return False

#######################################################################

    def startBeginJob(self, s):
        s = s.lower()
        if s.find("<beginjob>") >= 0:
            self.processingBeginJob = True
            return True
        return False

    def endBeginJob(self, s):
        s = s.lower()
        if s.find("</beginjob>") >= 0:
            self.processingBeginJob = False
            return True
        return False

    def isInBeginJob(self, s):
        if self.startBeginJob(s):
            self.processingBeginJob = True
        return self.processingBeginJob

    def processBeginJob(self, line):
        if self.endBeginJob(line):
            self.processingBeginJob = False
        else:
            line = line.strip()
            self.beginJobList.append(line)
            # print "self.beginJobList=",self.beginJobList

#######################################################################

    def startFinishJob(self, s):
        s = s.lower()
        if s.find("<finishjob>") >= 0:
            self.processingFinishJob = True
            return True
        return False

    def endFinishJob(self, s):
        s = s.lower()
        if s.find("</finishjob>") >= 0:
            self.processingFinishJob = False
            return True
        return False

    def isInFinishJob(self, s):
        if self.startFinishJob(s):
            self.processingFinishJob = True
        return self.processingFinishJob

    def processFinishJob(self, line):
        if self.endFinishJob(line):
            self.processingFinishJob = False
            self.finishJobList.append("mailer.py ")
        else:
            line = line.strip()
            self.finishJobList.append(line)
#######################################################################

    def startMacros(self, s):
        s = s.lower()
        if s.find("<macros>") >= 0:
            self.processingMacros = True
            return True
        return False

    def endMacros(self, s):
        s = s.lower()
        if s.find("</macros>") >= 0:
            self.processingMacros = False
            return True
        return False

    def isInMacros(self, s):
        if self.startMacros(s):
            self.processingMacros = True
        return self.processingMacros

    def processMacro(self, line):
        # print "processMacro input=",line
        if self.endMacros(line):
            self.processingMacros = False
        elif line.find("=") >= 0:
            [a, b] = line.split("=")
            a = a.strip()
            b = b.strip()
            self.macroList.append(a)
            self.macroDict[a] = b
            if (b.find("`") == 0):
                if (b.find("`", 1) == (len(b) - 1)):
                    cmd = b[1:len(b) - 1]
                    (retVal, val) = commands.getstatusoutput(cmd)
                    if retVal == 0:
                        self.macroDict[a] = val

#######################################################################

    def nameNode(self, elem):
        #global snum,pnum,jnum, nodeDict
        if elem.attrib.has_key('name'):
            self.nodeDict[elem.attrib['name']] = elem
            return
        if elem.tag == 'serial':
            elem.attrib['name'] = 'Serial_%s' % (self.snum)
            self.snum += 1
        if elem.tag == 'parallel':
            elem.attrib['name'] = 'Parallel_%s' % (self.pnum)
            self.pnum += 1
        if elem.tag == 'job':
            elem.attrib['name'] = 'Job_%s' % (self.jnum)
            self.jnum += 1
        if elem.tag == 'dag':
            elem.attrib['name'] = 'dag'
        self.nodeDict[elem.attrib['name']] = elem

    def labelTree(self, elem):
        self.nameNode(elem)
        l = list(elem)
        if len(l):
            for i2 in range(0, len(l)):
                x = l[i2]
                self.nameNode(x)
                l2 = list(x)
                if len(l2):
                    self.labelTree(x)

    def makeJobLists(self, elem):
        l = list(elem)
        if len(l):
            jlist = L()
            jlist.tag = elem.tag
            for x in l:
                jlist.append(x.attrib['name'])
                l2 = list(x)
                if len(l2):
                    self.makeJobLists(x)

        if len(jlist):
            jobs = " ".join(jlist)
            elem.attrib['joblist'] = jobs
            self.dagDict[elem.attrib['name']] = jlist

    def expand(self, jlist):
        for n, i in enumerate(jlist):
            if self.dagDict.get(str(i)):
                jlist[n] = self.dagDict.get(str(i))
        for n, i in enumerate(jlist):
            if isinstance(i, list):
                jlist[n] = self.expand(i)
        return jlist

    def getJobs(self, jlist, ndx=0):
        tag = getattr(jlist, 'tag', False)
        if tag == 'parallel':
            j = ''
            for j1 in jlist:
                j += self.getJobs(j1, ndx)
                j += ' '
            return j
        elif tag == 'serial':
            return self.getJobs(jlist[ndx], ndx)
        else:
            return jlist

    def generateParentChildList(self, jlist):
        par_or_ser = getattr(jlist, 'tag', False)
        if par_or_ser:
            for n, i in enumerate(jlist):

                if n == 0:
                    self.generateParentChildList(jlist[n])

                elif n > 0:

                    p = self.getJobs(jlist[n - 1], ndx=-1)
                    self.generateParentChildList(jlist[n - 1])

                    c = self.getJobs(jlist[n], ndx=0)
                    self.generateParentChildList(jlist[n])

                    if par_or_ser == 'serial':
                        pc = "parent %s child %s" % (p, c)
                        if pc not in self.pcList:
                            self.pcList.append(pc)

    def printJobRelationships(self, outFile):
        with open(outFile, "a") as f:
            for line in self.pcList:
                f.write("%s\n" % line)
        f.close()

    def reportState(self):
        print "processingSerial:%s processingParallel:%s" %\
            (self.processingSerial, self.processingParallel)
        print self.jobList
        print self.jobDict

    def digestInputFile(self, args):
        # strip out comments starting with '#'
        infile = args.inputFile
        xmlfile = "%s.xml" % infile
        r = re.compile("#.*")
        plist = []
        if len(sys.argv) > 1:
            f = open(infile, "r")
            x = open(xmlfile, "w")
            x.write("<dag>\n")
            i = 0
            j = 0
            for line in f:
                line = line.strip()
                line = r.sub('', line)
                # print "input line " , line
                if 'jobsub ' not in line and len(line) > 0:
                    x.write("%s\n" % line)

                if self.startSerial(line):
                    pass
                elif self.endSerial(line):
                    pass
                elif self.startParallel(line):
                    plist = []
                elif self.endParallel(line):
                    self.jobList.append(plist)
                elif self.isInMacros(line):
                    self.processMacro(line)
                elif self.isInBeginJob(line):
                    self.processBeginJob(line)
                elif self.isInFinishJob(line):
                    self.processFinishJob(line)

                elif len(line) > 0:
                    for mac in self.macroList:
                        line = line.replace(mac, self.macroDict[mac])
                    val = ""
                    j += 1
                    os.environ['JOBSUBJOBSECTION'] = "%s" % j
                    passedArgs = ' '.join(args.passedArgs)
                    passedArgs = """ -e JOBSUBJOBSECTION --lines '+JobsubJobSection=\\\"%s\\\"' %s """ % (
                        j, passedArgs)
                    repVal = "jobsub %s " % passedArgs
                    line = line.replace("jobsub ", repVal)
                    (retVal, val) = commands.getstatusoutput(line)
                    if retVal:
                        print "error processing command %s" % line
                        print val
                        sys.exit(1)
                    else:
                        condor_cmd = ''
                        condor_cmd_list = []
                        biglist = val.split()
                        ncmds = 0
                        i = 0
                        for word in biglist:
                            if word.find(".cmd") >= 0 and word not in condor_cmd_list:
                                ncmds = ncmds + 1
                                condor_cmd = word
                                jobName = "Jb_%d_%d" % (j, i)
                                x.write("""<job name="%s" cmd="%s" />\n""" %
                                        (jobName, condor_cmd))
                                self.jobNameList.append(jobName)
                                self.jobDict[condor_cmd] = jobName
                                self.jobNameDict[jobName] = condor_cmd
                                condor_cmd_list.append(condor_cmd)
                                i += 1
                        if self.processingSerial:
                            self.jobList.append(tuple(condor_cmd_list))
                        if self.processingParallel:
                            plist.append(tuple(condor_cmd_list))
                        if (self.redundancy != 0 and self.redundancy != len(condor_cmd_list)):
                            print "ERROR: different number of '.cmd' files detected"
                            print "between jobs in input file! This will generate"
                            print "an incorrect DAG!  aborting......"
                            # sys.exit(-1)
                            self.redundancy = len(condor_cmd_list)
                        else:
                            self.redundancy = len(condor_cmd_list)

                        # reportState()
            x.write('</dag>\n')
            x.close()
            tree = ET.parse(xmlfile)
            root = tree.getroot()
            self.labelTree(root)
            self. makeJobLists(root)

            cntr = 0
            for line in self.beginJobList:
                for mac in self.macroList:
                    line = line.replace(mac, self.macroDict[mac])
                    # print line
                    self.beginJobList[cntr] = line
                cntr += 1
            cntr = 0
            for line in self.finishJobList:
                for mac in self.macroList:
                    line = line.replace(mac, self.macroDict[mac])
                    # print line
                    self.finishJobList[cntr] = line
                cntr += 1

    def getJobName(self, jlist, i, j=0):

        if isinstance(jlist[i], tuple):
            retval = self.jobDict[jlist[i][j]]

        elif isinstance(jlist[i], list):
            retval = ""
            for l in jlist[i]:
                retval = retval + " " + self.getJobName(l, 0, j)
        else:

            retval = self.jobDict[jlist[j]]

        return retval

    def generateDependencies(self, outputFile, jlist):
        f = open(outputFile, "a")
        jend = len(jlist)
        i = 0

        if len(self.beginJobList) > 0:
            j = 0
            while(j < self.redundancy):
                l = "parent JOB_BEGIN child %s\n" % self.getJobName(
                    jlist, i, j)
                f.write(l)
                j += 1

        while (i < jend - 1):
            j = 0
            while(j < self.redundancy):
                l = "parent %s child %s\n" %\
                    (self.getJobName(jlist, i, j), self.getJobName(jlist, i + 1, j))
                f.write(l)
                j += 1
            i += 1

        if len(self.finishJobList) > 0:
            j = 0

            while(j < self.redundancy):
                l = "parent %s child JOB_FINISH\n" % self.getJobName(
                    jlist, i, j)
                f.write(l)
                j += 1

        f.close()

    def writeDummyCmdFile(self):

        now = datetime.datetime.now()
        filebase = "%s%02d%02d_%02d%02d%02d" % (now.year, now.month,
                                                now.day, now.hour,
                                                now.minute, now.second)
        cmd_file_name = "dummy%s.cmd" % (filebase)
        wrap_file_name = "returnOK_%s.sh" % (filebase)
        cmd_file = cmd_file_dummy % (filebase, filebase, 
                                     filebase,  filebase)

        f = open(cmd_file_name, "w")
        f.write(cmd_file)
        f.close()
        f = open(wrap_file_name, "w")
        f.write(wrap_file_dummy)
        f.close()
        os.chmod(wrap_file_name, stat.S_IRWXU | stat.S_IRGRP |
                 stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH)
        return cmd_file_name

    def generateDag(self, outputFile=None):

        f = open(outputFile, "w")
        l = "DOT %s.dot UPDATE\n" % os.path.basename(outputFile)
        f.write(l)

        if len(self.beginJobList) > 0:

            l = "JOB JOB_BEGIN %s\n" % self.writeDummyCmdFile()
            f.write(l)

        # for n in self.jobNameList:
        #    l = "JOB " + n + " "+ self.jobNameDict[n]+"\n"
        #    f.write(l)

        for k in sorted(self.nodeDict.keys()):
            e = self.nodeDict[k]
            if e.tag == 'job':
                f.write("JOB %s %s\n" % (k, os.path.basename(e.attrib['cmd'])))

        if len(self.finishJobList) > 0:
            time.sleep(1)
            l = "JOB JOB_FINISH %s \n" % self.writeDummyCmdFile()
            f.write(l)

        if len(self.beginJobList) > 0:
            l = "SCRIPT PRE JOB_BEGIN %s \n" % self.beginJobList[1]
            f.write(l)
        if len(self.finishJobList) > 0:
            l = "SCRIPT POST JOB_FINISH %s \n" % self.finishJobList[1]
            f.write(l)

        f.close()
        # self.generateDependencies(outputFile,self.jobList)
        jobList = L(self.dagDict.get('dag'), tag='serial')
        self.expand(jobList)
        self.generateParentChildList(jobList)
        self.printJobRelationships(outputFile)


# this should really use optparse but too many of the input
# options are malformed for optparse  - not enough dashes etc
# also --subgroups has to go both to this programs input and on to jobsub
#
# parse out the ones we intend to use and pass the rest on to jobsub
#
class ArgParser(object):

    def __init__(self, cfp):
        cfp.findConfigFile()
        self.inputFile = None
        self.outputFile = ""
        self.runDag = False
        self.viewDag = False
        self.maxJobs = 0
        self.passedArgs = None
        self.schedd = os.environ.get("SCHEDD")
        self.submitHost = os.environ.get("SUBMIT_HOST")
        self.group = os.environ.get("GROUP")
        self.subgroup = None
        self.passedArgs = []
        allowed = cfp.supportedGroups()

        if self.group not in allowed:
            print "ERROR do not run this script as member of group %s" % self.group
            print "export GROUP=one of %s and try again" % allowed
            sys.exit(-1)

        i = 0
        args = sys.argv
        passedArgs = []
        argLen = len(sys.argv)

        while i < argLen:
            arg = args[i]
            if arg in ["--h", "-h", "--help", "-help"]:
                self.printHelp()
            elif arg in ["-man", "-manual"]:
                self.printManual()
            elif arg in ["--inputFile", "-input_file", "-i"]:
                if os.path.isfile(args[i + 1]):
                    self.inputFile = args[i + 1]
                    i += 1
            elif arg in ["--outputFile", "-output_file", "-o"]:
                self.outputFile = args[i + 1]
                i += 1
            elif arg in ["--maxConcurrent", "--maxRunning", "-max_running", "-m"]:
                self.maxJobs = int(args[i + 1])
                i += 1
            elif arg in ["--submit", "-submit", "-s"]:
                self.runDag = True
            elif arg == "--subgroup":
                self.subgroup = args[i + 1]
                self.passedArgs.append("--subgroup")
                self.passedArgs.append(self.subgroup)
                i += 1

            elif i > 0:
                self.passedArgs.append(arg)
            i += 1

        if self.inputFile is None:
            i = 0
            fileOpts = ['-L', '--log_file',
                        '--tar_file_name', '-f', '-i', '-t']
            for arg in self.passedArgs:
                if os.path.isfile(arg):
                    if (i == 0) or ((i > 0) and (self.passedArgs[i - 1] not in fileOpts)):
                        self.inputFile = self.passedArgs[i]
                        del self.passedArgs[i]
                        break
                i += 1

        if self.outputFile == "":
            cmd = """date +%Y%m%d_%H%M%S"""
            # commands=JobUtils()
            (retVal, val) = commands.getstatusoutput(cmd)
            if retVal == 0:
                now = val.rstrip()
                condor_tmp = os.environ.get("CONDOR_TMP")
                home = os.environ.get("HOME")
                if condor_tmp == "" or condor_tmp == None:
                    self.outputFile = home + "/submit.%s.dag" % now
                else:
                    self.outputFile = condor_tmp + "/submit.%s.dag" % now
                # print "generated DAG saved as ", self.outputFile
            else:
                sys.stderr.write("error executing %s\n ") % cmd
                sys.stderr.write("%s\n ") % val
                sys.exit(1)

    def report(self):
        print "====================================="
        print "inputFile = ", self.inputFile
        print "outputFile = ", self.outputFile
        print "runDag =", self.runDag
        print "maxJobs =", self.maxJobs

    def printHelp(self):
        h = os.path.basename(sys.argv[0])
        helpFile = usage % (h, h)
        print helpFile
        sys.exit(0)

    def printManual(self):
        m = os.path.basename(sys.argv[0])
        df = """date +%Y%m%d_%H%M%S_%N"""
        manFile = manual % (m, df, m)
        print manFile
        sys.exit(0)


class JobRunner(object):

    def __init__(self):
        pass



    def munge_jdf(self,condor_jdf):
        files = ",".join(os.listdir("."))
        transfer_files = "transfer_input_files = %s" % files
        orig_name = condor_jdf + ".orig"
        os.rename(condor_jdf, orig_name)
        fin = open(orig_name, "r")
        fout = open(condor_jdf, "w")
        for line in fin:
            if  'queue' in line:
                fout.write("%s\n" % transfer_files)
            fout.write("%s" % line)
        fin.close()
        fout.close()




    def doSubmit(self, args=None):
        cmd = ""
        # commands=JobUtils()
        (retVal, host) = commands.getstatusoutput("uname -n")
        ups_shell = os.environ.get("UPS_SHELL")
        condor_tmp = os.environ.get("CONDOR_TMP")
        os.chdir(condor_tmp)
        remote_schedd = False
        local_schedd_name = ""
        if ups_shell is None:
            ups_shell = "sh"
        if args.schedd:
            parts = args.schedd.split('@')
            schedd_host = parts[-1]
            if schedd_host != args.submitHost:
                remote_schedd = True
            else:
                if parts[0] != parts[-1]:
                    local_schedd_name = parts[0]
        else:
            args.schedd = args.submitHost

        if local_schedd_name:
            cmd1 = "condor_config_val SCHEDD.%s.SCHEDD_ADDRESS_FILE" % local_schedd_name
            cmd2 = "condor_config_val SCHEDD.%s.SCHEDD_DAEMON_AD_FILE" % local_schedd_name
            (retVal, addr_file) = commands.getstatusoutput(cmd1)
            (retVal, daemon_file) = commands.getstatusoutput(cmd2)
            add_spec = " -schedd-address-file %s  -schedd-daemon-ad-file %s" % (addr_file, daemon_file)
        else:
            add_spec = ""
        cmd = """condor_submit_dag %s -no_submit -dont_suppress_notification  """ % add_spec
        if args.maxJobs > 0:
            cmd = cmd + " -maxjobs %d " % args.maxJobs
        usr = os.environ.get("USER")
        grp = os.environ.get("GROUP")

        subgroup = None
        if args is not None:
            subgroup = args.subgroup

        cmd += """ -append "+Owner=\\"%s\\"" """ % usr
        cmd += """ -append "+Jobsub_Submit_Dir=\\"%s\\"" """ % condor_tmp
        cmd += """ -append "+Jobsub_Submit_Host=\\"%s\\"" """ % args.submitHost
        if subgroup:
            cmd += """-append "+AccountingGroup=\\"group_%s.%s.%s\\"" """ %\
                (grp, subgroup, usr)
        else:
            cmd += """-append "+AccountingGroup=\\"group_%s.%s\\"" """ %\
                (grp, usr)
        cmd += """ -append "+JobsubJobID=\\"\$(Cluster).\$(Process)@%s\\"" """ % (
            args.schedd)
        cmd += os.path.basename(args.outputFile)
        print "executing %s " % cmd
        (retVal, val) = commands.getstatusoutput(cmd)
        if retVal:
            print "ERROR executing %s" % cmd
            print val
            retVal = retVal % 256
            if retVal == 0:
                retVal = 1
            #sys.exit(retVal)
        #print val
        condor_jdf = args.outputFile + ".condor.sub"
        if remote_schedd:
            self.munge_jdf(condor_jdf)
            cmd = "condor_submit -remote %s %s"%(args.schedd, condor_jdf)
        elif args.schedd:
            cmd = "condor_submit -name %s %s"%(args.schedd, condor_jdf)
        else:
            cmd = "condor_submit  %s"%(condor_jdf)
        print "executing %s " % cmd
        (retVal, val) = commands.getstatusoutput(cmd)
        if retVal:
            print "ERROR executing %s" % cmd
            print val
            retVal = retVal % 256
            if retVal == 0:
                retVal = 1
            sys.exit(retVal)
        print val
        


if __name__ == '__main__':
    c = JobsubConfigParser()
    args = ArgParser(c)
    d = DagParser()
    d.digestInputFile(args)
    d.generateDag(args.outputFile)
    if args.runDag:
        j = JobRunner()
        j.doSubmit(args)
